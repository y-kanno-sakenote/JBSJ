# -*- coding: utf-8 -*-
"""
è«–æ–‡æ¤œç´¢ãƒ‡ãƒ¢ï¼ˆè‘—è€…ã‚¯ãƒªãƒƒã‚¯ã§ãƒ•ã‚£ãƒ«ã‚¿è¿½åŠ ç‰ˆï¼‰
- æ¤œç´¢çµæœã«å‡ºã¦ããŸã€Œè‘—è€…ã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã§è‘—è€…ãƒ•ã‚£ãƒ«ã‚¿ã«è¿½åŠ ã§ãã‚‹ä»•çµ„ã¿
- st.dataframe ã¯ã‚»ãƒ«ã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–ã‚Œãªã„ãŸã‚ã€çµæœãƒ†ãƒ¼ãƒ–ãƒ«ä¸‹ã«è‘—è€…ãƒœã‚¿ãƒ³ç¾¤ã‚’ç”Ÿæˆã—ã¦å¯¾å¿œ
- CSVåˆ—: è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«, è‘—è€…, HPãƒªãƒ³ã‚¯å…ˆ, PDFãƒªãƒ³ã‚¯å…ˆ, summaryï¼ˆä»»æ„ï¼‰
"""

import re
from pathlib import Path
import time
import pandas as pd
import streamlit as st

st.set_page_config(page_title="è«–æ–‡æ¤œç´¢ï¼ˆè‘—è€…ã‚¯ãƒªãƒƒã‚¯è¿½åŠ ãƒ‡ãƒ¢ï¼‰", layout="wide")

AUTHOR_SPLIT_RE = re.compile(r"[;ï¼›,ã€ï¼Œ/ï¼|ï½œ]+")

def split_authors(cell):
    if cell is None:
        return []
    return [w.strip() for w in AUTHOR_SPLIT_RE.split(str(cell)) if w.strip()]

def norm_key(s: str) -> str:
    return re.sub(r"\s+", "", str(s or "")).lower().strip()

def build_author_candidates(df: pd.DataFrame):
    raw = df.get("è‘—è€…", pd.Series(dtype=str)).fillna("").tolist()
    authors = []
    for cell in raw:
        authors.extend(split_authors(cell))
    seen, uniq = set(), []
    for a in authors:
        k = norm_key(a)
        if k and k not in seen:
            seen.add(k)
            uniq.append(a)
    return sorted(uniq)

def ensure_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    return df

def load_demo_df() -> pd.DataFrame:
    demo = Path("data/keywords_summary4.csv")
    if demo.exists():
        try:
            df = pd.read_csv(demo, encoding="utf-8")
            return ensure_cols(df)
        except Exception:
            pass
    return pd.DataFrame([
        {"è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«":"æ¸…é…’ä¸­ã®ã‚¢ãƒŸãƒé…¸ã«é–¢ã™ã‚‹ç ”ç©¶","è‘—è€…":"å±±ç”°å¤ªéƒ; ä½è—¤èŠ±å­","HPãƒªãƒ³ã‚¯å…ˆ":"https://example.com/hp1","PDFãƒªãƒ³ã‚¯å…ˆ":"https://example.com/p1.pdf","summary":"æ¸…é…’ã®ã‚¢ãƒŸãƒé…¸çµ„æˆã¨å®˜èƒ½ç‰¹æ€§ã®é–¢ä¿‚ã‚’æ¦‚èª¬ã€‚"},
        {"è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«":"å‘³å™Œç™ºé…µã«ãŠã‘ã‚‹ä¹³é…¸èŒãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹","è‘—è€…":"ç”°ä¸­ä¸€éƒ","HPãƒªãƒ³ã‚¯å…ˆ":"https://example.com/hp2","PDFãƒªãƒ³ã‚¯å…ˆ":"https://example.com/p2.pdf","summary":"å‘³å™Œç™ºé…µä¸­ã®ä¹³é…¸èŒç¾¤é›†ã®æ¨ç§»ã¨ä»£è¬ç”£ç‰©ã‚’è§£æã€‚"},
        {"è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«":"ãƒ“ãƒ¼ãƒ«ã®ãƒ›ãƒƒãƒ—é¦™æˆåˆ†ã®å¤‰å‹•","è‘—è€…":"Suzuki Ken; ä½è—¤èŠ±å­","HPãƒªãƒ³ã‚¯å…ˆ":"https://example.com/hp3","PDFãƒªãƒ³ã‚¯å…ˆ":"https://example.com/p3.pdf","summary":"ãƒ‰ãƒ©ã‚¤ãƒ›ãƒƒãƒ”ãƒ³ã‚°æ¡ä»¶ã¨é¦™æ°—æˆåˆ†ã®é–¢ä¿‚ã‚’èª¿æŸ»ã€‚"}
    ])

with st.sidebar:
    st.header("ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿")
    up = st.file_uploader("CSVã‚’é¸æŠï¼ˆUTF-8ï¼‰", type=["csv"])
    use_demo = st.toggle("ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã†", value=True)

if up is not None:
    try:
        df = ensure_cols(pd.read_csv(up, encoding="utf-8"))
        st.toast("CSVã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    except Exception as e:
        st.error(f"CSVã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
        st.stop()
elif use_demo:
    df = load_demo_df()
else:
    st.info("å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§CSVã‚’æŒ‡å®šã™ã‚‹ã‹ãƒ‡ãƒ¢ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

if "summary" not in df.columns:
    df["summary"] = ""

st.title("è«–æ–‡æ¤œç´¢")

if "authors_sel" not in st.session_state:
    st.session_state["authors_sel"] = []

col_a, col_kw = st.columns([1.2, 2.0])

with col_a:
    authors_all = build_author_candidates(df)
    authors_sel = st.multiselect(
        "è‘—è€…ï¼ˆè¤‡æ•°é¸æŠï¼‰",
        authors_all,
        default=st.session_state["authors_sel"],
        key="authors_multiselect"
    )

with col_kw:
    kw = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ï¼summary ã‚’éƒ¨åˆ†ä¸€è‡´ï¼‰", value="")

def apply_filters(_df: pd.DataFrame) -> pd.DataFrame:
    df2 = _df.copy()
    if st.session_state["authors_sel"]:
        sel = {norm_key(a) for a in st.session_state["authors_sel"]}
        def hit_author(v):
            return any(norm_key(x) in sel for x in split_authors(v))
        df2 = df2[df2["è‘—è€…"].apply(hit_author)]
    if kw.strip():
        q = norm_key(kw)
        mask = df2["è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«"].astype(str).str.lower().str.contains(q) | \
               df2["summary"].astype(str).str.lower().str.contains(q)
        df2 = df2[mask]
    return df2

filtered = apply_filters(df)

def short_summary(s: str, n=120):
    s = str(s or "").strip()
    return (s[:n] + "â€¦") if len(s) > n else s

disp = filtered.copy()
disp["summary(è¦ç´„)"] = disp["summary"].apply(short_summary)

cols_order = [c for c in ["è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«","è‘—è€…","HPãƒªãƒ³ã‚¯å…ˆ","PDFãƒªãƒ³ã‚¯å…ˆ","summary(è¦ç´„)"] if c in disp.columns]
disp = disp[cols_order]

st.markdown(f"### æ¤œç´¢çµæœï¼ˆ{len(disp)} ä»¶ï¼‰")
st.dataframe(disp, use_container_width=True, hide_index=True)

st.divider()
with st.expander("ğŸ‘† çµæœã«å‡ºãŸè‘—è€…ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ã«è¿½åŠ ", expanded=False):
    author_cells = filtered.get("è‘—è€…", pd.Series(dtype=str)).fillna("").astype(str).tolist()
    cand_authors = []
    for cell in author_cells:
        cand_authors.extend(split_authors(cell))
    uniq_authors, seen = [], set()
    for a in cand_authors:
        k = norm_key(a)
        if k and k not in seen:
            seen.add(k)
            uniq_authors.append(a)
    if not uniq_authors:
        st.caption("ï¼ˆã“ã®æ¤œç´¢çµæœã«ã¯è‘—è€…åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰")
    else:
        st.caption("ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ä¸Šéƒ¨ã®ã€è‘—è€…ï¼ˆè¤‡æ•°é¸æŠï¼‰ã€ã«è¿½åŠ ã•ã‚Œã¾ã™ã€‚")
        def _add_author(name: str):
            st.session_state["authors_sel"] = sorted(set(st.session_state["authors_sel"]) | {name})
            st.session_state["authors_multiselect"] = st.session_state["authors_sel"]
        per_row = 6
        rows = [uniq_authors[i:i+per_row] for i in range(0, len(uniq_authors), per_row)]
        for row in rows:
            cols = st.columns(per_row, gap="small")
            for col, name in zip(cols, row):
                with col:
                    st.button(
                        f"ï¼‹ {name}",
                        key=f"add_author_{hash(name)}",
                        use_container_width=True,
                        on_click=_add_author,
                        args=(name,)
                    )
        if st.session_state["authors_sel"]:
            st.info("ç¾åœ¨é¸æŠä¸­ã®è‘—è€…: " + " / ".join(st.session_state["authors_sel"]))

col_d1, col_d2 = st.columns(2)
with col_d1:
    st.download_button(
        "ğŸ“¥ ç¾åœ¨ã®çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=filtered.to_csv(index=False).encode("utf-8-sig"),
        file_name=f"results_{time.strftime('%Y%m%d')}.csv",
        mime="text/csv",
        use_container_width=True
    )
with col_d2:
    st.download_button(
        "ğŸ“¥ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=df.to_csv(index=False).encode("utf-8-sig"),
        file_name=f"all_{time.strftime('%Y%m%d')}.csv",
        mime="text/csv",
        use_container_width=True
    )
